import os
import json
import numpy as np
from PIL import Image
from PIL.PngImagePlugin import PngInfo
import folder_paths
from datetime import datetime
import piexif
import piexif.helper
from comfy.cli_args import args
import hashlib

class FileNaming:
    def __init__(self):
        self.output_dir = folder_paths.get_output_directory()
        self.type = "output"

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "images": ("IMAGE",),
            },
            "optional": {
                "metadata": ("METADATA",),
                "workflow": ("WORKFLOW",),
                "any1": ("*", {"forceInput": True}),
                "any2": ("*", {"forceInput": True}),
                "any3": ("*", {"forceInput": True}),
            },
            "hidden": {
                "prompt": "PROMPT",
                "extra_pnginfo": "EXTRA_PNGINFO",
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("images", "filepath")
    FUNCTION = "save_images"
    OUTPUT_NODE = True
    CATEGORY = "üîµTOO-Pack/image"

    def _parse_date_tokens(self, text):
        if not text:
            return text
        now = datetime.now()
        if 'timestamp' in text:
            text = text.replace('timestamp', str(int(now.timestamp())))

        replacements = {
            "YYYY": now.strftime("%Y"),
            "YY": now.strftime("%y"),
            "MM": now.strftime("%m"),
            "DD": now.strftime("%d"),
            "HH": now.strftime("%H"),
            "mm": now.strftime("%M"),
            "ss": now.strftime("%S")
        }

        for token, value in replacements.items():
            text = text.replace(token, value)
        return text

    def _safe_path(self, path):
        """
        Nettoie un chemin de fichier en retirant les caract√®res invalides.
        """
        if not path:
            return path
        
        # S√©parer le chemin en r√©pertoire et nom de fichier
        directory = os.path.dirname(path)
        filename = os.path.basename(path)
        
        # Caract√®res invalides dans les noms de fichiers (Windows/Linux/Mac)
        invalid = '<>:"|?*\n\r\t'
        # Pour le nom de fichier, nettoyer tous les caract√®res invalides
        clean_filename = "".join(c for c in filename if c not in invalid).strip()
        
        # Pour le r√©pertoire, on garde les s√©parateurs de chemin
        # On nettoie juste les \n, \r, \t
        clean_directory = directory.replace('\n', '').replace('\r', '').replace('\t', '').strip()
        
        # Reconstruire le chemin
        if clean_directory:
            return os.path.join(clean_directory, clean_filename)
        return clean_filename
    
    def _calculate_file_hash(self, filepath, hash_length=12):
        """
        Calculate SHA256 hash of a file and return first N characters.
        Used for model_hash and lora_hashes in A1111 format.
        """
        try:
            # Try to find the actual file path
            # ComfyUI stores models in various directories
            possible_paths = []
            
            # If it's already a full path and exists
            if os.path.isfile(filepath):
                possible_paths.append(filepath)
            else:
                # Try to find in ComfyUI directories
                filename = os.path.basename(filepath)
                
                # Check in checkpoints folder
                checkpoints_dir = folder_paths.get_folder_paths("checkpoints")
                for cp_dir in checkpoints_dir:
                    full_path = os.path.join(cp_dir, filepath)
                    if os.path.isfile(full_path):
                        possible_paths.append(full_path)
                
                # Check in loras folder
                loras_dir = folder_paths.get_folder_paths("loras")
                for lora_dir in loras_dir:
                    full_path = os.path.join(lora_dir, filepath)
                    if os.path.isfile(full_path):
                        possible_paths.append(full_path)
            
            # Use the first valid path found
            if not possible_paths:
                return ""
            
            actual_path = possible_paths[0]
            
            # Calculate SHA256 hash
            sha256_hash = hashlib.sha256()
            with open(actual_path, "rb") as f:
                # Read in chunks to handle large files
                for byte_block in iter(lambda: f.read(4096), b""):
                    sha256_hash.update(byte_block)
            
            # Return first N characters of hex digest
            return sha256_hash.hexdigest()[:hash_length]
        except Exception as e:
            # If hash calculation fails, return empty string
            print(f"Warning: Could not calculate hash for {filepath}: {e}")
            return ""

    def _calculate_lora_hash(self, filepath):
        """
        Calculate SHA256 hash of a lora file excluding safetensors metadata (compatible A1111/Civitai AutoV3).
        Returns first 12 characters of the hash.
        """
        try:
            # Try to find the actual file path (same logic as _calculate_file_hash)
            possible_paths = []

            if os.path.isfile(filepath):
                possible_paths.append(filepath)
            else:
                filename = os.path.basename(filepath)

                # Check in checkpoints folder
                checkpoints_dir = folder_paths.get_folder_paths("checkpoints")
                for cp_dir in checkpoints_dir:
                    full_path = os.path.join(cp_dir, filepath)
                    if os.path.isfile(full_path):
                        possible_paths.append(full_path)

                # Check in loras folder
                loras_dir = folder_paths.get_folder_paths("loras")
                for lora_dir in loras_dir:
                    full_path = os.path.join(lora_dir, filepath)
                    if os.path.isfile(full_path):
                        possible_paths.append(full_path)

            if not possible_paths:
                return ""

            actual_path = possible_paths[0]

            # Calculate SHA256 hash excluding safetensors metadata
            hash_sha256 = hashlib.sha256()
            blksize = 1024 * 1024

            with open(actual_path, "rb") as f:
                header = f.read(8)
                n = int.from_bytes(header, "little")
                offset = n + 8
                f.seek(offset)

                for chunk in iter(lambda: f.read(blksize), b""):
                    hash_sha256.update(chunk)

            return hash_sha256.hexdigest()[:12]

        except Exception as e:
            print(f"Warning: Could not calculate lora hash for {filepath}: {e}")
            return ""

    def _build_a111_params(self, metadata, width, height):
        """Build A1111/Civitai format metadata string"""
        # Get prompts and clean newlines (replace \n with space)
        positive = metadata.get("positive", "").strip()
        positive = " ".join(positive.split())  # Replace all whitespace (including \n) with single space
        
        negative = metadata.get("negative", "").strip()
        negative = " ".join(negative.split())  # Replace all whitespace (including \n) with single space
        
        seed = metadata.get("seed")
        steps = metadata.get("steps")
        cfg = metadata.get("cfg")
        sampler_name = metadata.get("sampler_name", "").strip()
        scheduler = metadata.get("scheduler", "").strip()
        model_name = metadata.get("model_name", "").strip()
        model_hash = metadata.get("model_hash", "").strip()
        lora_hashes = metadata.get("lora_hashes", {})
        custom = metadata.get("custom", "").strip()

        parts = []
        if positive:
            parts.append(positive)
        if negative:
            parts.append(f"Negative prompt: {negative}")

        params_parts = []
        if steps:
            params_parts.append(f"Steps: {steps}")
        if sampler_name:
            sampler_str = f"Sampler: {sampler_name}"
            if scheduler:
                sampler_str += f" {scheduler}"
            params_parts.append(sampler_str)
        if cfg:
            params_parts.append(f"CFG scale: {cfg}")
        if seed is not None:
            params_parts.append(f"Seed: {seed}")
        if width and height:
            params_parts.append(f"Size: {width}x{height}")
        if custom:
            params_parts.append(custom)
        if model_hash:
            params_parts.append(f"Model hash: {model_hash}")
        if model_name:
            params_parts.append(f"Model: {model_name}")
        if lora_hashes:
            if isinstance(lora_hashes, dict):
                lora_str = ", ".join([f"{name}: {h}" for name, h in lora_hashes.items()])
                params_parts.append(f'Lora hashes: "{lora_str}"')
            elif isinstance(lora_hashes, str):
                params_parts.append(f'Lora hashes: "{lora_hashes}"')

        params_parts.append("Version: ComfyUI")

        if params_parts:
            parts.append(", ".join(params_parts))

        return "\n".join(parts) if parts else ""

    def _get_image_dimensions(self, tensor):
        if len(tensor.shape) >= 2:
            height, width = tensor.shape[0], tensor.shape[1]
            return int(width), int(height)
        return None, None

    def _extract_from_prompt(self, extraction_pattern, prompt):
        """
        Extract widget value from prompt.
        Supports:
        - #123:widget_name (simple node ID)
        - #270:268:widget_name (subgraph node ID with : separator)
        - ClassName:widget_name (class type search)
        Returns list of values for multiline strings, or single value as string.
        """
        if not prompt or not extraction_pattern:
            return ""

        extraction_pattern = extraction_pattern.strip()

        if ":" not in extraction_pattern:
            return ""

        # Check if starts with # (node ID extraction)
        if extraction_pattern.startswith("#"):
            # Remove the #
            pattern_without_hash = extraction_pattern[1:]

            # Find the last : which separates node_id from widget_name
            # Example: "270:268:ckpt_name" -> node_id="270:268", widget="ckpt_name"
            last_colon_idx = pattern_without_hash.rfind(":")
            if last_colon_idx == -1:
                return ""

            node_id = pattern_without_hash[:last_colon_idx]
            widget_name = pattern_without_hash[last_colon_idx + 1:]

            # Look for this node_id in prompt
            if node_id in prompt:
                node_data = prompt[node_id]
                inputs = node_data.get("inputs", {})
                value = inputs.get(widget_name, "")
                
                # Handle multiline strings - split by newlines and return list
                if isinstance(value, str) and '\n' in value:
                    lines = [line.strip() for line in value.split('\n') if line.strip()]
                    return lines if lines else ""
                
                return str(value) if value else ""
            return ""

        # Class name search: ClassName:widget_name
        else:
            parts = extraction_pattern.split(":", 1)
            if len(parts) != 2:
                return ""

            class_search = parts[0].lower()
            widget_name = parts[1]

            for node_id in prompt:
                node_data = prompt[node_id]
                class_type = node_data.get("class_type", "")

                if class_search in class_type.lower():
                    inputs = node_data.get("inputs", {})
                    value = inputs.get(widget_name, "")
                    
                    # Handle multiline strings - split by newlines and return list
                    if isinstance(value, str) and '\n' in value:
                        lines = [line.strip() for line in value.split('\n') if line.strip()]
                        return lines if lines else ""
                    
                    return str(value) if value else ""
            return ""

    def save_images(self, images, metadata=None, workflow=None, any1=None, any2=None, any3=None, prompt=None, extra_pnginfo=None):
        config = self._get_config(extra_pnginfo)

        # Convert any inputs to strings if provided
        any1_value = str(any1).strip() if any1 is not None else ""
        any2_value = str(any2).strip() if any2 is not None else ""
        any3_value = str(any3).strip() if any3 is not None else ""
        
        # Map for easy lookup
        any_values = {
            "[any1]": any1_value,
            "[any2]": any2_value,
            "[any3]": any3_value
        }

        # Build metadata dict from data_fields
        meta_dict = {}
        if metadata and isinstance(metadata, dict):
            meta_dict = metadata.copy()

        # Extract data_fields values
        data_fields = config.get("data_fields", [])
        for field in data_fields:
            name = field.get("name", "")
            value = field.get("value", "")

            if not name:
                continue

            # If value is [any1], [any2], or [any3], use the corresponding input value
            if value.strip() in any_values:
                value_from_any = any_values[value.strip()]
                if value_from_any:
                    meta_dict[name] = value_from_any
            # If value contains extraction pattern (#id:widget or ClassName:widget)
            elif value and ":" in value and (value.startswith("#") or not value.startswith("%")):
                extracted = self._extract_from_prompt(value, prompt)
                if extracted:
                    # Handle both single values and lists (for multiline strings)
                    if isinstance(extracted, list):
                        meta_dict[name] = "\n".join(extracted)
                    else:
                        meta_dict[name] = extracted
            # If value from metadata input
            elif name in meta_dict:
                pass  # Keep existing value
            # If static value
            elif value:
                meta_dict[name] = value

        # Extract model if configured
        model_extract = config.get("model_extract", "")
        if model_extract:
            # If model_extract is [any1], [any2], or [any3], use corresponding input value
            if model_extract.strip() in any_values:
                model_value = any_values[model_extract.strip()]
            else:
                model_value = self._extract_from_prompt(model_extract, prompt)
            
            if model_value:
                model_name = os.path.splitext(os.path.basename(model_value))[0]
                meta_dict["model"] = model_name
                if "model_name" not in meta_dict:
                    meta_dict["model_name"] = model_name
                
                # Calculate model hash
                if "model_hash" not in meta_dict:
                    model_hash = self._calculate_file_hash(model_value, 10)
                    if model_hash:
                        meta_dict["model_hash"] = model_hash

        # Extract loras if configured
        loras_extracts = config.get("loras_extracts", [])
        lora_names = []
        lora_hashes_dict = {}
        for lora_extract in loras_extracts:
            if lora_extract:
                # If lora_extract is [any1], [any2], or [any3], use corresponding input value
                if lora_extract.strip() in any_values:
                    lora_value = any_values[lora_extract.strip()]
                    # Split by newlines to handle multiple loras from any input
                    if lora_value and isinstance(lora_value, str):
                        lora_value = [line.strip() for line in lora_value.split('\n') if line.strip()]
                else:
                    lora_value = self._extract_from_prompt(lora_extract, prompt)
                
                # Handle both single values and lists (for multiline strings)
                lora_values = lora_value if isinstance(lora_value, list) else [lora_value] if lora_value else []
                
                for lora_val in lora_values:
                    if lora_val:
                        lora_name = os.path.splitext(os.path.basename(lora_val))[0]
                        lora_names.append(lora_name)
                        
                        # Calculate lora hash (compatible Civitai/A1111 - excludes safetensors metadata)
                        lora_hash = self._calculate_lora_hash(lora_val)
                        if lora_hash:
                            lora_hashes_dict[lora_name] = lora_hash

        if lora_names:
            meta_dict["loras"] = ", ".join(lora_names)
        
        # Add lora_hashes to metadata if we calculated any
        if lora_hashes_dict and "lora_hashes" not in meta_dict:
            meta_dict["lora_hashes"] = lora_hashes_dict

        # Apply text replacements by target
        replacements = config.get("text_replace_pairs", [])
        for pair in replacements:
            target = pair.get("target", "")
            input_str = pair.get("input", "")
            output_str = pair.get("output", "")

            if not input_str:
                continue

            # If target is [any1], [any2], or [any3], treat as no target (replace in all fields)
            if target in any_values:
                target = ""
            
            # If target specified, only replace in that field
            if target and target in meta_dict:
                value = str(meta_dict[target])
                meta_dict[target] = value.replace(input_str, output_str)
            # If no target, replace in all fields
            elif not target:
                for key in meta_dict:
                    value = str(meta_dict[key])
                    meta_dict[key] = value.replace(input_str, output_str)

        # Build filename
        filename_parts = []
        separator = config.get("separator", "_")

        # Pre-parse date variables (ONLY for %date1, %date2, etc.)
        date_vars = {
            "%date1": self._parse_date_tokens(config.get("date1", "")),
            "%date2": self._parse_date_tokens(config.get("date2", "")),
            "%date3": self._parse_date_tokens(config.get("date3", ""))
        }

        output_folder = ""
        for field in ["output_folder", "prefix", "extra1", "extra2", "extra3", "model", "suffix"]:
            value = config.get(field, "")
            if not value:
                continue

            # If value is [any1], [any2], or [any3], use the corresponding input value
            if value.strip() in any_values:
                value_from_any = any_values[value.strip()]
                if value_from_any:
                    value = value_from_any
                else:
                    continue  # Skip if any not connected
            # Replace date vars (%date1, %date2, etc.)
            elif value in date_vars:
                value = date_vars[value]
            # Replace metadata field names with their values
            elif value in meta_dict:
                value = str(meta_dict[value])
            # Otherwise keep as is (static text)

            if field == "output_folder":
                output_folder = value
            elif value:
                filename_parts.append(value)

        # Setup output dir
        output_dir = self.output_dir
        if output_folder:
            output_folder = self._safe_path(output_folder)
            output_dir = os.path.join(output_dir, output_folder)
            os.makedirs(output_dir, exist_ok=True)

        filename_base = separator.join(filename_parts) if filename_parts else "output"
        filename_base = self._safe_path(filename_base)

        # Get settings
        output_format = config.get("output_format", "webp")
        quality = config.get("quality", 95)
        embed_workflow = config.get("embed_workflow", True)
        save_metadata = config.get("save_metadata", True)

        # Save images
        saved_paths = []
        for i, image in enumerate(images):
            if len(images) > 1:
                filename = f"{filename_base}_{i:04d}.{output_format}"
            else:
                filename = f"{filename_base}.{output_format}"

            filepath = os.path.join(output_dir, filename)

            counter = 1
            while os.path.exists(filepath):
                filename = f"{filename_base}_{counter:03d}.{output_format}"
                filepath = os.path.join(output_dir, filename)
                counter += 1

            # Convert to PIL
            i_np = 255. * image.cpu().numpy()
            img = Image.fromarray(np.clip(i_np, 0, 255).astype(np.uint8))

            # Get A1111 params
            a111_params = None
            if save_metadata and meta_dict:
                width, height = self._get_image_dimensions(image)
                a111_params = self._build_a111_params(meta_dict, width, height)

            # Save
            if output_format == "png":
                self._save_png(img, filepath, a111_params, workflow, prompt, extra_pnginfo, embed_workflow)
            else:
                self._save_webp_jpeg(img, filepath, output_format, quality, a111_params, workflow, prompt, extra_pnginfo, embed_workflow)

            saved_paths.append(filepath)

        return (images, saved_paths[0] if saved_paths else "")

    def _get_config(self, extra_pnginfo):
        config = {
            "separator": "_",
            "output_format": "webp",
            "quality": 95,
            "embed_workflow": True,
            "save_metadata": True,
            "date1": "YYYY-MM-DD",
            "date2": "HHmmss",
            "date3": "",
            "text_replace_pairs": [],
            "data_fields": [],
            "model_extract": "",
            "loras_extracts": []
        }

        if extra_pnginfo and "workflow" in extra_pnginfo:
            try:
                wf = json.loads(extra_pnginfo["workflow"]) if isinstance(extra_pnginfo["workflow"], str) else extra_pnginfo["workflow"]
                nodes = wf.get("nodes", [])
                for node in nodes:
                    if node.get("type") in ["FileNaming", "FileNaming (LiteGraph)", "FileNaming (DOM)"]:
                        config.update(node.get("properties", {}))
                        config["text_replace_pairs"] = node.get("text_replace_pairs", [])
                        config["data_fields"] = node.get("data_fields", [])
                        break
            except:
                pass

        return config

    def _save_png(self, img, filepath, a111_params, workflow, prompt, extra_pnginfo, embed_workflow):
        if args.disable_metadata:
            img.save(filepath)
            return

        pnginfo = PngInfo()

        if a111_params:
            pnginfo.add_text("parameters", a111_params)

        if embed_workflow:
            if workflow and isinstance(workflow, dict):
                wf_extra = workflow.get("extra_pnginfo")
                wf_prompt = workflow.get("prompt")
                if wf_extra:
                    for k, v in wf_extra.items():
                        pnginfo.add_text(k, json.dumps(v) if not isinstance(v, str) else v)
                if wf_prompt:
                    pnginfo.add_text("prompt", json.dumps(wf_prompt))
            else:
                if extra_pnginfo:
                    for k, v in extra_pnginfo.items():
                        pnginfo.add_text(k, json.dumps(v) if not isinstance(v, str) else v)
                if prompt:
                    pnginfo.add_text("prompt", json.dumps(prompt))

        img.save(filepath, pnginfo=pnginfo)

    def _save_webp_jpeg(self, img, filepath, output_format, quality, a111_params, workflow, prompt, extra_pnginfo, embed_workflow):
        if output_format == "webp":
            img.save(filepath, quality=quality, method=6)
        else:
            img.save(filepath, quality=quality)

        if args.disable_metadata:
            return

        # Construire le dictionnaire EXIF avec la technique multi-tag
        pnginfo_json = {}
        prompt_json = {}

        # Workflow ComfyUI distribu√© sur plusieurs tags EXIF si demand√©
        if embed_workflow:
            # Si workflow est fourni en entr√©e, l'utiliser en priorit√©
            if workflow and isinstance(workflow, dict):
                wf_extra_pnginfo = workflow.get("extra_pnginfo")
                wf_prompt = workflow.get("prompt")

                if wf_extra_pnginfo is not None:
                    pnginfo_json = {
                        piexif.ImageIFD.Make - i: f"{k}:{json.dumps(v, separators=(',', ':'))}"
                        for i, (k, v) in enumerate(wf_extra_pnginfo.items())
                    }

                if wf_prompt is not None:
                    prompt_json = {
                        piexif.ImageIFD.Model: f"prompt:{json.dumps(wf_prompt, separators=(',', ':'))}"
                    }
            else:
                # Sinon, utiliser le workflow courant
                if extra_pnginfo is not None:
                    pnginfo_json = {
                        piexif.ImageIFD.Make - i: f"{k}:{json.dumps(v, separators=(',', ':'))}"
                        for i, (k, v) in enumerate(extra_pnginfo.items())
                    }

                if prompt is not None:
                    prompt_json = {
                        piexif.ImageIFD.Model: f"prompt:{json.dumps(prompt, separators=(',', ':'))}"
                    }

        # Construire le dictionnaire EXIF complet
        exif_dict = {}

        # Section "0th" pour workflow (multi-tag)
        if pnginfo_json or prompt_json:
            exif_dict["0th"] = pnginfo_json | prompt_json

        # Section "Exif" pour les param√®tres A1111
        if a111_params:
            exif_dict["Exif"] = {
                piexif.ExifIFD.UserComment: piexif.helper.UserComment.dump(
                    a111_params,
                    encoding="unicode"
                )
            }

        # G√©n√©rer et ins√©rer les donn√©es EXIF
        if exif_dict:
            try:
                exif_bytes = piexif.dump(exif_dict)

                # V√©rification de taille pour JPEG
                if output_format in ["jpg", "jpeg"]:
                    MAX_EXIF_SIZE = 65535
                    if len(exif_bytes) > MAX_EXIF_SIZE:
                        print(f"‚ö†Ô∏è M√©tadonn√©es trop volumineuses ({len(exif_bytes)} bytes) pour JPEG (max {MAX_EXIF_SIZE})")
                        # Essayer sans le workflow
                        exif_dict_minimal = {}
                        if a111_params:
                            exif_dict_minimal["Exif"] = {
                                piexif.ExifIFD.UserComment: piexif.helper.UserComment.dump(
                                    a111_params,
                                    encoding="unicode"
                                )
                            }
                        if exif_dict_minimal:
                            exif_bytes = piexif.dump(exif_dict_minimal)
                            if len(exif_bytes) <= MAX_EXIF_SIZE:
                                piexif.insert(exif_bytes, filepath)
                                print("   ‚Üí M√©tadonn√©es A1111 sauvegard√©es (workflow omis)")
                            else:
                                print("   ‚Üí Impossible de sauvegarder les m√©tadonn√©es")
                        return

                piexif.insert(exif_bytes, filepath)
            except Exception as e:
                print(f"Could not save EXIF metadata: {e}")

NODE_CLASS_MAPPINGS = {
    "FileNaming (LiteGraph)": FileNaming,
    "FileNaming (DOM)": FileNaming
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "FileNaming (LiteGraph)": "üíæ TOO Smart Image Saver (Advanced)(LiteGraph)",
    "FileNaming (DOM)": "üíæ TOO Smart Image Saver (Advanced)(DOM)"
}